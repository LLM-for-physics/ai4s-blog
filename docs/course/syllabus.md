# 课程大纲

### 第 1 周 （9 月 8 日）
AI 概览、LLM 概览、API 配置和 Python 开发实践。

### 第 2 周 （9 月 15 日）
LLM 的局限性、提示此工程、Tool calling、RAG

### 第 3 周 （9 月 22 日）
逻辑推理、Agent 工作流、基于 Agent 的开发实践。

### 第 4 周 （9 月 29 日）
机器学习基础、决策树与随机森林、神经网络与优化

### 第 5 周 （10 月 13 日）
CNN、RNN、Transformer 架构

<!-- ## 模块一：AIGC 与 LLM (第1-3周)

### 课程目标
了解大语言模型（LLM）的工作原理，掌握其核心应用方法（提示工程、Agent、RAG等），并能通过实践项目解决实际问题。

### 基础概念入门（What & Why）
- LLM 简介
  - 生成、总结与翻译、问答、对话、逻辑推理、写代码、……
- LLM 的局限性
  - 会“胡说八道”（幻觉-Hallucination）、知识滞后、可能存在偏见、提示（输入）敏感、……
- Prompt 工程
  - 什么是提示（Prompt）？
  - 基础技巧：清晰明确、提供上下文、指定角色、使用分隔符、零样本（Zero-Shot）、少样本（Few-Shot）
  - 思维链（Chain-of-Thought）：让模型“一步一步想”，尤其适用于数学或逻辑问题。

**实践环节**
- 在阿里云百炼控制台购买 API Key（或申请学生优惠）
- 查阅官方文档了解有哪些参数，通过 HTTP 请求调用 LLM API
- 配置本地 python 环境，编写 Python 程序，实现与 LLM 的单轮对话和多轮对话
- 作业：每个同学收到助教分发的 api key（不可外传或滥用），登陆服务器、准备 python 环境，实现一个对话小项目（目的是让大家熟悉使用服务器、开发项目和提交作业的流程）。

### Agent 技术

- Tool Calling：LLM 与各种工具的交互对话。
  - 克服 LLM 在计算任务和算法任务方面的缺陷。
  - MCP 协议：将实用工具按照统一协议打包成 MCP Server，使 LLM 能够遵循协议访问工具。
- RAG 检索增强生成
  - 解决 LLM 知识滞后和幻觉问题
  - 应用：智能客服、企业知识库问答、学习助手。
- Agent 工作流
  - 工作流平台：用 Dify、Coze 等工作流可视化平台来做更形象直观的展示。（这种工作流平台利于概念的快速实现和理解，但不利于最终的生产实践）
  - 讲 tool calling、RAG 等功能集成到一个工作流里，实现复杂的功能，比如 AI 编程助手、deep research 等。

**实践环节**
- 构建一个 mcp server，它的功能是输入一个 sympy 表达式和每个符号的取值，目标是代入求值。
- 使用 langchain 实现一个简单的 RAG 应用（助教提前准备好向量数据库材料）。
- 助教演示 cline 用 AI 编程助手来帮助构建项目，带大家理解 AI-编程助手的工作流是怎么设计的、有哪些重要的 tool-calling 要素。
- 逸思论坛（招募学生内测，免费使用并提供反馈）
- 作业（主题自由，同学们可以选自己感兴趣的去做）：
  - 1. 构建 agent 工作流来做数据清洗和段落切割预处理
  - 2. 以 RAG 为核心，构建提问+检索+答题的 agent
  - 3. 基于 mcp server 实现一个 coding agent
  - 4. 用 openai sdk 内置的 tool calling 实现一个 coding agent
  - 5. 构造一个小的物理问题 benchmark （5~10 题）

### 扩展话题（可选）
- LLM for Math：形式语言（Alpha Geometry、DeepMind Alpha-Proof、字节跳动 Seed-Prover）、自然语言（DeepMind 和 OpenAI 相关研究）
- LLM for Physics：PhyBench（LLM 在物理竞赛题上的表现和局限性）

## 模块二：机器学习基本原理 (第4-6周)

### 神经网络数学原理
- 算子（线性层、激活元）、通用近似定理
- 梯度计算与反向传播算法，损失函数和优化算法
- CNN、RNN 等网络结构

**实践环节**
- Pytorch 使用
- 作业：待定

### LLM 进阶知识
- 语言模型的网络架构（Transformer）
- Scaling Law 理论
- 模型训练（预训练、微调、后训练）
- 评估方法（Benchmark）
- 扩展话题：
  - 大模型对齐技术（RLHF：ChatGPT 的训练方法），对齐（alignment）指的是让大语言模型的行为、输出和决策方式与其设计者(人类操作者)的意图、价值观和指令保持一致的过程。
  - 伦理与安全（模型偏见、数据安全、攻击方式……）

### 算法

## 模块三：AI for science (第7-8周)

## 模块四：AI 在物理学当中的应用 (第9-16周) -->


*课程大纲可能根据实际教学进度进行微调，具体变动将及时通知学生。*
