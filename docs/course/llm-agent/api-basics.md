# æ¨¡å—ä¸€ï¼šLLM API è°ƒç”¨åŸºç¡€

## ğŸ“– æ¦‚è¿°

æœ¬æ¨¡å—å°†æ·±å…¥ä»‹ç»å¤§è¯­è¨€æ¨¡å‹ API çš„è°ƒç”¨åŸç†ï¼Œå¸®åŠ©åŒå­¦ä»¬ç†è§£å¦‚ä½•ä¸ä¸åŒçš„ LLM ä¾›åº”å•†è¿›è¡Œäº¤äº’ã€‚æˆ‘ä»¬å°†ä»æœ€åŸºç¡€çš„æ¦‚å¿µå¼€å§‹ï¼Œé€æ­¥æŒæ¡å®é™…çš„ç¼–ç¨‹æŠ€èƒ½ã€‚

## ğŸ” LLM API è°ƒç”¨åŸç†

### ä»€ä¹ˆæ˜¯ APIï¼Ÿ

APIï¼ˆApplication Programming Interfaceï¼Œåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼‰æ˜¯ä¸åŒè½¯ä»¶ç»„ä»¶ä¹‹é—´é€šä¿¡çš„æ¡¥æ¢ã€‚LLM API å…è®¸æˆ‘ä»¬é€šè¿‡ç½‘ç»œè¯·æ±‚ä¸å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚

### HTTP è¯·æ±‚åŸºç¡€

LLM API åŸºäº HTTP åè®®å·¥ä½œï¼Œä¸»è¦ä½¿ç”¨ POST æ–¹æ³•ï¼š

```python
import requests
import json

# åŸºæœ¬çš„ HTTP POST è¯·æ±‚ç»“æ„
url = "https://api.openai.com/v1/chat/completions"
headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
}
data = {
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello, world!"}]
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
```

### æµå¼å“åº” vs æ‰¹é‡å“åº”

LLM API æ”¯æŒä¸¤ç§å“åº”æ¨¡å¼ï¼š

**æ‰¹é‡å“åº”**ï¼šç­‰å¾…å®Œæ•´å›ç­”åä¸€æ¬¡æ€§è¿”å›
```python
# æ‰¹é‡å“åº”ç¤ºä¾‹
response = requests.post(url, headers=headers, json=data)
result = response.json()
print(result['choices'][0]['message']['content'])
```

**æµå¼å“åº”**ï¼šå®æ—¶è¿”å›ç”Ÿæˆçš„å†…å®¹
```python
# æµå¼å“åº”ç¤ºä¾‹
data["stream"] = True
response = requests.post(url, headers=headers, json=data, stream=True)

for line in response.iter_lines():
    if line:
        chunk = json.loads(line.decode('utf-8').split('data: ')[1])
        if chunk['choices'][0]['delta'].get('content'):
            print(chunk['choices'][0]['delta']['content'], end='')
```

## ğŸ”‘ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### Base URLï¼ˆåŸºç¡€ URLï¼‰

Base URL æ˜¯ API æœåŠ¡çš„æ ¹åœ°å€ï¼Œä¸åŒä¾›åº”å•†æœ‰ä¸åŒçš„ç«¯ç‚¹ï¼š

```python
# ä¸åŒä¾›åº”å•†çš„ Base URL
OPENAI_BASE_URL = "https://api.openai.com/v1"
ANTHROPIC_BASE_URL = "https://api.anthropic.com/v1"
AZURE_BASE_URL = "https://your-resource.openai.azure.com"

# è‡ªå®šä¹‰éƒ¨ç½²ç¤ºä¾‹
CUSTOM_BASE_URL = "https://your-custom-deployment.com/v1"
```

**ä½¿ç”¨åœºæ™¯**ï¼š
- å®˜æ–¹ API æœåŠ¡
- ç§æœ‰åŒ–éƒ¨ç½²
- ä»£ç†æœåŠ¡
- é•œåƒæœåŠ¡

### API Keyï¼ˆAPI å¯†é’¥ï¼‰

API Key æ˜¯èº«ä»½è®¤è¯çš„å‡­è¯ï¼Œç¡®ä¿åªæœ‰æˆæƒç”¨æˆ·æ‰èƒ½è®¿é—®æœåŠ¡ã€‚

#### å®‰å…¨æœ€ä½³å®è·µ

1. **ç¯å¢ƒå˜é‡å­˜å‚¨**
```python
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è·å– API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
```

2. **åˆ›å»º .env æ–‡ä»¶**
```bash
# .env æ–‡ä»¶å†…å®¹
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
ZHIPU_API_KEY=your-zhipu-key-here
```

3. **é…ç½® .gitignore**
```gitignore
# ç¡®ä¿ä¸æäº¤æ•æ„Ÿä¿¡æ¯
.env
*.key
config/secrets.json
```

## ğŸ¢ ä¸»æµ LLM ä¾›åº”å•†å¯¹æ¯”

### OpenAI

**ç‰¹ç‚¹**ï¼š
- æœ€æˆç†Ÿçš„ API ç”Ÿæ€
- æ¨¡å‹ç§ç±»ä¸°å¯Œï¼ˆGPT-3.5, GPT-4, GPT-4 Turboï¼‰
- æ”¯æŒå‡½æ•°è°ƒç”¨ã€å›¾åƒç†è§£ç­‰é«˜çº§åŠŸèƒ½

**API ç¤ºä¾‹**ï¼š
```python
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}
    ],
    temperature=0.7,
    max_tokens=1000
)

print(response.choices[0].message.content)
```

**å®šä»·æ¨¡å¼**ï¼šæŒ‰ token è®¡è´¹ï¼Œè¾“å…¥å’Œè¾“å‡º token ä»·æ ¼ä¸åŒ

### Anthropic (Claude)

**ç‰¹ç‚¹**ï¼š
- Constitutional AI æŠ€æœ¯ï¼Œæ›´å®‰å…¨å¯é 
- é•¿ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆClaude-2 æ”¯æŒ 100K tokensï¼‰
- ä¼˜ç§€çš„æ¨ç†å’Œåˆ†æèƒ½åŠ›

**API ç¤ºä¾‹**ï¼š
```python
import anthropic

client = anthropic.Anthropic(api_key="your-api-key")

message = client.messages.create(
    model="claude-3-sonnet-20240229",
    max_tokens=1000,
    temperature=0.7,
    messages=[
        {"role": "user", "content": "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†"}
    ]
)

print(message.content[0].text)
```

### Google (Gemini)

**ç‰¹ç‚¹**ï¼š
- å¤šæ¨¡æ€èƒ½åŠ›å¼ºï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ï¼‰
- ä¸ Google ç”Ÿæ€ç³»ç»Ÿæ·±åº¦é›†æˆ
- å…è´¹é¢åº¦ç›¸å¯¹è¾ƒé«˜

**API ç¤ºä¾‹**ï¼š
```python
import google.generativeai as genai

genai.configure(api_key="your-api-key")
model = genai.GenerativeModel('gemini-pro')

response = model.generate_content("è§£é‡Šæ·±åº¦å­¦ä¹ çš„å·¥ä½œåŸç†")
print(response.text)
```

## ğŸ› ï¸ é”™è¯¯å¤„ç†å’Œæœ€ä½³å®è·µ

### å¸¸è§é”™è¯¯å¤„ç†

```python
import time
import random
from typing import Optional

def call_llm_with_retry(client: LLMClient, messages: List[Dict[str, str]], 
                       max_retries: int = 3, backoff_factor: float = 1.0) -> Optional[str]:
    """å¸¦é‡è¯•æœºåˆ¶çš„ LLM è°ƒç”¨"""
    
    for attempt in range(max_retries):
        try:
            return client.chat(messages)
            
        except requests.exceptions.RequestException as e:
            if "rate limit" in str(e).lower():
                # é€Ÿç‡é™åˆ¶ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
                wait_time = backoff_factor * (2 ** attempt) + random.uniform(0, 1)
                print(f"é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.2f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                
            elif attempt == max_retries - 1:
                print(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè°ƒç”¨å¤±è´¥: {e}")
                return None
                
            else:
                print(f"è¯·æ±‚å¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•: {e}")
                time.sleep(1)
                
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}")
            return None
    
    return None
```

## ğŸ“ ç»ƒä¹ ä½œä¸š

1. ä½¿ç”¨ä¸åŒçš„ LLM ä¾›åº”å•† API å®ç°ç›¸åŒçš„å¯¹è¯åŠŸèƒ½
2. å®ç°ä¸€ä¸ªæ”¯æŒå¤šä¾›åº”å•†çš„ç»Ÿä¸€ LLM å®¢æˆ·ç«¯
3. æ·»åŠ é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶

## ğŸ”— ç›¸å…³èµ„æº

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs)
- [Anthropic API æ–‡æ¡£](https://docs.anthropic.com/)
- [Google AI Studio](https://makersuite.google.com/)

---

**ä¸‹ä¸€æ­¥**ï¼šå­¦ä¹  [é«˜çº§ç”¨æ³•æ¢ç´¢](./advanced-usage.md)ï¼ŒæŒæ¡ Prompt å·¥ç¨‹å’Œå¤šè½®å¯¹è¯ç®¡ç†æŠ€å·§ã€‚
