#!/usr/bin/env python3
"""
æµ‹è¯•å®Œæ•´çš„ RAG Agent
éªŒè¯æ–‡æ¡£ä¸­çš„ RAG Agent ç±»ä»£ç æ˜¯å¦æ­£ç¡®
"""

import chromadb
from chromadb.utils import embedding_functions
import openai
import os
from dotenv import load_dotenv
from typing import List, Dict, Any

class RAGAgent:
    """RAG Agent ç±»ï¼ˆæ¥è‡ªåŸæ–‡æ¡£ï¼‰"""
    def __init__(self, collection, openai_api_key: str, openai_base_url: str = None):
        self.collection = collection
        # æ ¹æ®ç”¨æˆ·è¦æ±‚æ·»åŠ  base_url æ”¯æŒ
        if openai_base_url:
            self.client = openai.OpenAI(api_key=openai_api_key, base_url=openai_base_url)
        else:
            self.client = openai.OpenAI(api_key=openai_api_key)
    
    def retrieve(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results,
            include=["documents", "metadatas", "distances"]
        )
        
        retrieved_docs = []
        for doc, metadata, distance in zip(
            results["documents"][0],
            results["metadatas"][0],
            results["distances"][0]
        ):
            retrieved_docs.append({
                "content": doc,
                "metadata": metadata,
                "similarity": 1 - distance
            })
        
        return retrieved_docs
    
    def generate_response(self, query: str, retrieved_docs: List[Dict[str, Any]]) -> str:
        """åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆå›ç­”"""
        context = "\n".join([f"æ–‡æ¡£ {i+1}: {doc['content']}" 
                           for i, doc in enumerate(retrieved_docs)])
        
        prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

ç›¸å…³æ–‡æ¡£:
{context}

ç”¨æˆ·é—®é¢˜: {query}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®å›ç­”:"""

        response = self.client.chat.completions.create(
            model="deepseek-v3",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜çš„åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
    
    def query(self, question: str, n_results: int = 3) -> Dict[str, Any]:
        """å®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹"""
        retrieved_docs = self.retrieve(question, n_results)
        answer = self.generate_response(question, retrieved_docs)
        
        return {
            "question": question,
            "answer": answer,
            "sources": retrieved_docs
        }

def test_rag_agent():
    """æµ‹è¯•å®Œæ•´çš„ RAG Agent"""
    print("=" * 50)
    print("æµ‹è¯• 4: å®Œæ•´ RAG Agent")
    print("=" * 50)
    
    try:
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
        client = chromadb.PersistentClient(path="./chroma_db")
        print("âœ“ Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # ä½¿ç”¨ OpenAI åµŒå…¥å‡½æ•°
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        
        if not api_key or api_key == "your-openai-api-key-here":
            print("âŒ OPENAI_API_KEY æœªæ­£ç¡®è®¾ç½®ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=api_key,
            api_base=base_url,
            model_name="text-embedding-v4"
        )
        
        # è·å–ç°æœ‰é›†åˆ
        try:
            collection = client.get_collection(
                name="knowledge_base",
                embedding_function=openai_ef
            )
            print(f"âœ“ è·å–é›†åˆæˆåŠŸï¼Œæ–‡æ¡£æ•°é‡: {collection.count()}")
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–é›†åˆï¼Œè¯·å…ˆè¿è¡Œ test_collection.py: {str(e)}")
            return False
        
        if collection.count() == 0:
            print("âŒ é›†åˆä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ test_collection.py æ·»åŠ æ–‡æ¡£")
            return False
        
        # åˆ›å»º RAG Agent
        rag_agent = RAGAgent(collection, api_key, base_url)
        print("âœ“ RAG Agent åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_question = "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
        print(f"\næµ‹è¯•é—®é¢˜: {test_question}")
        print("-" * 50)
        
        result = rag_agent.query(test_question)
        
        print("é—®é¢˜:", result["question"])
        print("\nå›ç­”:", result["answer"])
        print(f"\nå¼•ç”¨æ¥æº ({len(result['sources'])} ä¸ª):")
        for i, source in enumerate(result["sources"], 1):
            print(f"{i}. ç›¸ä¼¼åº¦: {source['similarity']:.3f}")
            print(f"   ä¸»é¢˜: {source['metadata']['topic']}")
            print(f"   å†…å®¹: {source['content'][:100]}...")
            print()
        
        # éªŒè¯ç»“æœ - ä¿®å¤éªŒè¯é€»è¾‘ï¼Œç›¸ä¼¼åº¦å¯ä»¥æ˜¯è´Ÿæ•°
        if (result["answer"] and 
            len(result["sources"]) > 0 and 
            isinstance(result["answer"], str) and 
            len(result["answer"].strip()) > 0):
            print("âœ“ RAG Agent æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("âŒ RAG Agent æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return False

if __name__ == "__main__":
    success = test_rag_agent()
    if success:
        print("\nğŸ‰ RAG Agent æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ RAG Agent æµ‹è¯•å¤±è´¥ï¼")
