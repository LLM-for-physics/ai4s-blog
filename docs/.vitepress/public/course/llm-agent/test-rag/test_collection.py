#!/usr/bin/env python3
"""
æµ‹è¯•é›†åˆåˆ›å»ºå’Œæ–‡æ¡£æ·»åŠ 
éªŒè¯æ–‡æ¡£ä¸­çš„é›†åˆæ“ä½œä»£ç æ˜¯å¦æ­£ç¡®
"""

import chromadb
from chromadb.utils import embedding_functions
import os
from dotenv import load_dotenv

def test_collection_operations():
    """æµ‹è¯•é›†åˆåˆ›å»ºå’Œæ–‡æ¡£æ·»åŠ """
    print("=" * 50)
    print("æµ‹è¯• 2: é›†åˆåˆ›å»ºå’Œæ–‡æ¡£æ·»åŠ ")
    print("=" * 50)
    
    try:
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
        client = chromadb.PersistentClient(path="./chroma_db")
        print("âœ“ Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # ä½¿ç”¨ OpenAI åµŒå…¥å‡½æ•°
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        
        if not api_key or api_key == "your-openai-api-key-here":
            print("âŒ OPENAI_API_KEY æœªæ­£ç¡®è®¾ç½®ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=api_key,
            api_base=base_url,
            model_name="text-embedding-v4"
        )
        print("âœ“ OpenAI åµŒå…¥å‡½æ•°åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºé›†åˆï¼ˆå¦‚æœå­˜åœ¨åˆ™åˆ é™¤é‡å»ºï¼‰
        try:
            client.delete_collection(name="knowledge_base")
            print("âœ“ åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ")
        except:
            pass
        
        collection = client.create_collection(
            name="knowledge_base",
            embedding_function=openai_ef,
            metadata={
                "description": "æˆ‘çš„çŸ¥è¯†åº“",
                "created": "2024-01-01"
            }
        )
        print(f"âœ“ é›†åˆåˆ›å»ºæˆåŠŸï¼Œå½“å‰æ–‡æ¡£æ•°é‡: {collection.count()}")
        
        # ç¤ºä¾‹æ–‡æ¡£ï¼ˆæ¥è‡ªåŸæ–‡æ¡£ï¼‰
        documents = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œä¸“æ³¨äºè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚",
            "è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚"
        ]
        
        # ç”Ÿæˆå”¯ä¸€ ID å’Œå…ƒæ•°æ®
        ids = [f"doc_{i}" for i in range(len(documents))]
        metadatas = [
            {"topic": "AI", "level": "basic"},
            {"topic": "ML", "level": "basic"},
            {"topic": "DL", "level": "intermediate"},
            {"topic": "NLP", "level": "intermediate"},
            {"topic": "CV", "level": "intermediate"}
        ]
        
        # æ·»åŠ æ–‡æ¡£åˆ°é›†åˆ
        collection.add(ids=ids, documents=documents, metadatas=metadatas)
        print(f"âœ“ æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
        print(f"âœ“ é›†åˆä¸­ç°æœ‰æ–‡æ¡£æ•°é‡: {collection.count()}")
        
        # éªŒè¯æ–‡æ¡£æ˜¯å¦æ­£ç¡®æ·»åŠ 
        if collection.count() == len(documents):
            print("âœ“ æ–‡æ¡£æ•°é‡éªŒè¯é€šè¿‡")
            return True
        else:
            print(f"âŒ æ–‡æ¡£æ•°é‡ä¸åŒ¹é…ï¼ŒæœŸæœ›: {len(documents)}, å®é™…: {collection.count()}")
            return False
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return False

if __name__ == "__main__":
    success = test_collection_operations()
    if success:
        print("\nğŸ‰ é›†åˆæ“ä½œæµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ é›†åˆæ“ä½œæµ‹è¯•å¤±è´¥ï¼")
