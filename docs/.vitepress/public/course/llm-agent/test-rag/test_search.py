#!/usr/bin/env python3
"""
æµ‹è¯•æœç´¢åŠŸèƒ½
éªŒè¯æ–‡æ¡£ä¸­çš„æŸ¥è¯¢å’Œæ£€ç´¢ä»£ç æ˜¯å¦æ­£ç¡®
"""

import chromadb
from chromadb.utils import embedding_functions
import os
from dotenv import load_dotenv

def search_knowledge_base(collection, query: str, n_results: int = 3):
    """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£ï¼ˆæ¥è‡ªåŸæ–‡æ¡£çš„å‡½æ•°ï¼‰"""
    results = collection.query(
        query_texts=[query],
        n_results=n_results,
        include=["documents", "metadatas", "distances"]
    )
    
    print(f"æŸ¥è¯¢: {query}")
    print("-" * 50)
    
    for i, (doc, metadata, distance) in enumerate(zip(
        results["documents"][0],
        results["metadatas"][0], 
        results["distances"][0]
    )):
        print(f"ç»“æœ {i+1} (ç›¸ä¼¼åº¦: {1-distance:.3f}):")
        print(f"ä¸»é¢˜: {metadata['topic']}, éš¾åº¦: {metadata['level']}")
        print(f"å†…å®¹: {doc}")
        print()
    
    return results

def test_search_functionality():
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    print("=" * 50)
    print("æµ‹è¯• 3: æœç´¢åŠŸèƒ½")
    print("=" * 50)
    
    try:
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
        client = chromadb.PersistentClient(path="./chroma_db")
        print("âœ“ Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # ä½¿ç”¨ OpenAI åµŒå…¥å‡½æ•°
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        
        if not api_key or api_key == "your-openai-api-key-here":
            print("âŒ OPENAI_API_KEY æœªæ­£ç¡®è®¾ç½®ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=api_key,
            api_base=base_url,
            model_name="text-embedding-v4"
        )
        
        # è·å–ç°æœ‰é›†åˆ
        try:
            collection = client.get_collection(
                name="knowledge_base",
                embedding_function=openai_ef
            )
            print(f"âœ“ è·å–é›†åˆæˆåŠŸï¼Œæ–‡æ¡£æ•°é‡: {collection.count()}")
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–é›†åˆï¼Œè¯·å…ˆè¿è¡Œ test_collection.py: {str(e)}")
            return False
        
        if collection.count() == 0:
            print("âŒ é›†åˆä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ test_collection.py æ·»åŠ æ–‡æ¡£")
            return False
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        test_queries = [
            "ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ",
            "æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„å…³ç³»",
            "è®¡ç®—æœºè§†è§‰çš„åº”ç”¨",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯"
        ]
        
        all_tests_passed = True
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- æµ‹è¯•æŸ¥è¯¢ {i} ---")
            try:
                search_results = search_knowledge_base(collection, query)
                
                # éªŒè¯æœç´¢ç»“æœ
                if (search_results["documents"] and 
                    len(search_results["documents"][0]) > 0):
                    print(f"âœ“ æŸ¥è¯¢ '{query}' è¿”å›äº† {len(search_results['documents'][0])} ä¸ªç»“æœ")
                    
                    # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†æ•°
                    distances = search_results["distances"][0]
                    similarities = [1 - d for d in distances]
                    print(f"âœ“ ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: {min(similarities):.3f} - {max(similarities):.3f}")
                    
                else:
                    print(f"âŒ æŸ¥è¯¢ '{query}' æ²¡æœ‰è¿”å›ç»“æœ")
                    all_tests_passed = False
                    
            except Exception as e:
                print(f"âŒ æŸ¥è¯¢ '{query}' å¤±è´¥: {str(e)}")
                all_tests_passed = False
        
        return all_tests_passed
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return False

if __name__ == "__main__":
    success = test_search_functionality()
    if success:
        print("\nğŸ‰ æœç´¢åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ æœç´¢åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼")
